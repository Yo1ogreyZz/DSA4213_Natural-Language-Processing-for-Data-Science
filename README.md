# DSA4213 Natural Language Processing for Data Science

This is an assignment code library, intended for reference, learning and communication. The class period is the Sem1 of the 2025 fall, and the lecturer is Doudou Zhou.

**”Quizzes“** are part of the class assignment and **are included in the grade**. **"Exercise"** refers to class exercises and will **not be included in the final grade.**

## Assignment1

### Objective:

-  Understand and implement key word embedding algorithms 
- Train embeddings using real corpora 
- Compare model outputs via qualitative and optional quantitative analyses 
- Practice scientific reporting and reproducible research

### Overview:

-  **Individual assignment**

- **Report:** PDF with embedded figures and appendix for code

- **Deliverables:** 

  1. Algorithm explanation

  2. Data preprocessing
  3. Model training + visualization
  4. Comparison and analysis

### Algorithms to implement

- **Skip-gram**
- **SPPMI-SVD**
- **GloVe**

   Each model should be trained on the same corpus and compared fairly.

   Corpus option: anything that you feel interesting, for example, English Wikipedia, https://www.gutenberg.org/, ...

### Required analysis

-  **Nearest neighbors** for selected words
- **Qualitative evaluation:** Are the similar words reasonable? 
- **t-SNE/UMAP/PCA visualization** of embedding space
- **Comparison across models:** what differs, what patterns arise?

### Bonus opportunities

- Benchmark evaluation (e.g., WordSim-353, analogy tasks)
- Using embeddings for text classification or clustering
- Discovering interesting phenomena: semantic drift, gender bias, etc.